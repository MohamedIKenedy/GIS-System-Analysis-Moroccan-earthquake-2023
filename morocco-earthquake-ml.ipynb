{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning-Based Analysis of the 2023 Morocco Earthquake Using Maxar Satellite Imagery**\n",
    "\n",
    "This notebook demonstrates how to use Maxar Open Data satellite imagery to perform automated damage assessment using deep learning models. We'll use pre- and post-earthquake imagery to detect and classify building damage.\n",
    "\n",
    "The analysis combines:\n",
    "- Maxar high-resolution satellite imagery\n",
    "- Building footprint detection\n",
    "- Change detection\n",
    "- Damage classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting leafmap\n",
      "  Using cached leafmap-0.42.6-py2.py3-none-any.whl (513 kB)\n",
      "Collecting geopandas\n",
      "  Using cached geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Collecting cogeo-mosaic\n",
      "  Using cached cogeo_mosaic-8.0.0-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "     ------------------------------------ 203.1/203.1 MB 990.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torchvision in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.16.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting segmentation-models-pytorch\n",
      "  Using cached segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\n",
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp310-cp310-win_amd64.whl (25.4 MB)\n",
      "     ---------------------------------------- 25.4/25.4 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.1)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.1-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 12.9/12.9 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     ---------------------------------------- 11.1/11.1 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opencv-python in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0.66)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Collecting colour\n",
      "  Using cached colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting ipyleaflet\n",
      "  Using cached ipyleaflet-0.19.2-py3-none-any.whl (31 kB)\n",
      "Collecting pystac-client\n",
      "  Using cached pystac_client-0.8.5-py3-none-any.whl (41 kB)\n",
      "Collecting ipyfilechooser\n",
      "  Using cached ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
      "Collecting scooby\n",
      "  Using cached scooby-0.10.0-py3-none-any.whl (18 kB)\n",
      "Collecting bqplot\n",
      "  Using cached bqplot-0.12.44-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting duckdb\n",
      "  Downloading duckdb-1.1.3-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     ---------------------------------------- 11.0/11.0 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting whiteboxgui\n",
      "  Using cached whiteboxgui-2.3.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from leafmap) (3.5.1)\n",
      "Collecting ipyvuetify\n",
      "  Using cached ipyvuetify-1.10.0-py2.py3-none-any.whl (6.1 MB)\n",
      "Collecting folium\n",
      "  Using cached folium-0.19.4-py2.py3-none-any.whl (110 kB)\n",
      "Collecting gdown\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Collecting xyzservices\n",
      "  Using cached xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "Collecting ipyevents\n",
      "  Using cached ipyevents-2.0.2-py3-none-any.whl (101 kB)\n",
      "Collecting anywidget\n",
      "  Using cached anywidget-0.9.13-py3-none-any.whl (213 kB)\n",
      "Collecting python-box\n",
      "  Downloading python_box-7.3.0-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from leafmap) (8.0.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from leafmap) (5.9.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from leafmap) (5.12.0)\n",
      "Collecting geojson\n",
      "  Using cached geojson-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting pyshp\n",
      "  Using cached pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting pyogrio>=0.7.2\n",
      "  Downloading pyogrio-0.10.0-cp310-cp310-win_amd64.whl (16.2 MB)\n",
      "     ---------------------------------------- 16.2/16.2 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting pyproj>=3.3.0\n",
      "  Downloading pyproj-3.7.0-cp310-cp310-win_amd64.whl (6.2 MB)\n",
      "     ---------------------------------------- 6.2/6.2 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: shapely>=2.0.0 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: cachetools in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cogeo-mosaic) (5.2.1)\n",
      "Collecting supermorecado\n",
      "  Using cached supermorecado-0.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: click in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cogeo-mosaic) (8.1.3)\n",
      "Collecting pydantic-settings~=2.0\n",
      "  Using cached pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Collecting rio-tiler<8.0,>=7.0\n",
      "  Using cached rio_tiler-7.3.0-py3-none-any.whl (265 kB)\n",
      "Requirement already satisfied: attrs in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cogeo-mosaic) (22.1.0)\n",
      "Collecting httpx\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting pydantic~=2.0\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Collecting morecantile\n",
      "  Using cached morecantile-6.2.0-py3-none-any.whl (49 kB)\n",
      "Collecting cligj\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Collecting click-plugins\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.11.0)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Collecting huggingface-hub>=0.24\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "     -------------------------------------- 450.7/450.7 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting efficientnet-pytorch>=0.6.1\n",
      "  Using cached efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting timm>=0.9\n",
      "  Using cached timm-1.0.13-py3-none-any.whl (2.4 MB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from segmentation-models-pytorch) (4.64.0)\n",
      "Collecting pretrainedmodels>=0.7.1\n",
      "  Using cached pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from segmentation-models-pytorch) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rasterio) (2021.10.8)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rasterio) (3.0.7)\n",
      "Collecting affine\n",
      "  Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2021.3)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->cogeo-mosaic) (0.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\mohamed\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.27.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "     -------------------------------------- 161.8/161.8 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting munch\n",
      "  Using cached munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.21.0\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting color-operations\n",
      "  Downloading color_operations-0.1.6-cp310-cp310-win_amd64.whl (133 kB)\n",
      "     -----------------------                 81.9/133.3 kB 7.5 kB/s eta 0:00:07\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1273, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1129, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 419, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 373, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 204, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -U leafmap geopandas cogeo-mosaic torch torchvision segmentation-models-pytorch rasterio numpy pandas scikit-learn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages\n",
    "import leafmap.foliumap as leafmap\n",
    "import torch\n",
    "import torchvision\n",
    "import segmentation_models_pytorch as smp\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(url):\n",
    "    \"\"\"Load and preprocess satellite image from URL\"\"\"\n",
    "    with rasterio.open(url) as src:\n",
    "        img = src.read([1,2,3])  # Read RGB bands\n",
    "        img = np.moveaxis(img, 0, -1)  # Convert to HWC format\n",
    "        img = cv2.resize(img, (512, 512))  # Resize to consistent size\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pre and post event imagery\n",
    "gdf = leafmap.maxar_items(\n",
    "    collection_id=\"Morocco-Earthquake-Sept-2023\",\n",
    "    child_id=\"10300100ECC53700\",\n",
    "    return_gdf=True,\n",
    "    assets=[\"visual\"]\n",
    ")\n",
    "\n",
    "before_images = gdf[gdf[\"datetime\"] < \"2023-09-10\"][\"visual\"].tolist()\n",
    "after_images = gdf[gdf[\"datetime\"] >= \"2023-09-10\"][\"visual\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingDetectionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "building_detector = BuildingDetectionModel()\n",
    "# In practice, you would load pre-trained weights here\n",
    "# building_detector.load_state_dict(torch.load('building_detector_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Change Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeDetectionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Siamese network architecture\n",
    "        self.encoder = torchvision.models.resnet34(pretrained=True)\n",
    "        self.encoder.fc = torch.nn.Identity()  # Remove classification head\n",
    "        \n",
    "        self.change_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512 * 2, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        # Extract features from both images\n",
    "        feat1 = self.encoder(x1)\n",
    "        feat2 = self.encoder(x2)\n",
    "        # Concatenate and compute change score\n",
    "        combined = torch.cat([feat1, feat2], dim=1)\n",
    "        return self.change_head(combined)\n",
    "\n",
    "change_detector = ChangeDetectionModel()\n",
    "# change_detector.load_state_dict(torch.load('change_detector_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Damage Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DamageClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50(pretrained=True)\n",
    "        self.model.fc = torch.nn.Linear(2048, 4)  # 4 damage levels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "damage_classifier = DamageClassifier()\n",
    "# damage_classifier.load_state_dict(torch.load('damage_classifier_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Complete Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_damage(before_url, after_url):\n",
    "    \"\"\"Complete pipeline for damage analysis\"\"\"\n",
    "    # Load and preprocess images\n",
    "    before_img = load_and_preprocess_image(before_url)\n",
    "    after_img = load_and_preprocess_image(after_url)\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    before_tensor = torch.from_numpy(before_img).permute(2,0,1).unsqueeze(0)\n",
    "    after_tensor = torch.from_numpy(after_img).permute(2,0,1).unsqueeze(0)\n",
    "    \n",
    "    # Detect buildings\n",
    "    with torch.no_grad():\n",
    "        building_mask = building_detector(after_tensor)\n",
    "        \n",
    "        # Detect changes\n",
    "        change_score = change_detector(before_tensor, after_tensor)\n",
    "        \n",
    "        # Classify damage for detected buildings\n",
    "        damage_pred = damage_classifier(after_tensor)\n",
    "    \n",
    "    return {\n",
    "        'building_mask': building_mask.squeeze().numpy(),\n",
    "        'change_score': change_score.item(),\n",
    "        'damage_class': torch.argmax(damage_pred).item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(before_url, after_url, results):\n",
    "    \"\"\"Create visualization of analysis results\"\"\"\n",
    "    damage_classes = ['No Damage', 'Minor', 'Major', 'Destroyed']\n",
    "    \n",
    "    m = leafmap.Map()\n",
    "    \n",
    "    # Add before/after imagery\n",
    "    m.split_map(before_url, after_url)\n",
    "    \n",
    "    # Overlay building detection mask\n",
    "    m.add_raster(results['building_mask'], layer_name='Buildings')\n",
    "    \n",
    "    # Add damage classification results\n",
    "    damage_level = damage_classes[results['damage_class']]\n",
    "    m.add_text(f\"Damage Level: {damage_level}\")\n",
    "    m.add_text(f\"Change Score: {results['change_score']:.2f}\")\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sample image pair\n",
    "sample_before = before_images[0]\n",
    "sample_after = after_images[0]\n",
    "\n",
    "results = analyze_damage(sample_before, sample_after)\n",
    "m = visualize_results(sample_before, sample_after, results)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_analyze_region(before_images, after_images):\n",
    "    \"\"\"Analyze multiple image pairs and aggregate results\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for before_url, after_url in zip(before_images, after_images):\n",
    "        try:\n",
    "            analysis = analyze_damage(before_url, after_url)\n",
    "            results.append({\n",
    "                'before_url': before_url,\n",
    "                'after_url': after_url,\n",
    "                **analysis\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {before_url}: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch analysis\n",
    "results_df = batch_analyze_region(before_images[:5], after_images[:5])\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
